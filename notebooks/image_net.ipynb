{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08944a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct as st\n",
    "import numpy as np\n",
    "\n",
    "from net import *\n",
    "from net.util import relu, d_relu, cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4926cdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "# Helper function to parse IDX files\n",
    "def parse_idx(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        magic = st.unpack('>I', file.read(4))[0]  # Magic number (4 bytes)\n",
    "        num_items = st.unpack('>I', file.read(4))[0]  # Number of items (4 bytes)\n",
    "\n",
    "        if magic == 2051:  # Magic number for images\n",
    "            num_rows = st.unpack('>I', file.read(4))[0]\n",
    "            num_cols = st.unpack('>I', file.read(4))[0]\n",
    "            num_bytes = num_items * num_rows * num_cols\n",
    "            data = np.frombuffer(file.read(num_bytes), dtype=np.uint8)\n",
    "            return data.reshape(num_items, num_rows, num_cols)\n",
    "        elif magic == 2049:  # Magic number for labels\n",
    "            data = np.frombuffer(file.read(num_items), dtype=np.uint8)\n",
    "            return data\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown magic number: {magic}\")\n",
    "\n",
    "# Parse the training data\n",
    "x_train = parse_idx('../data/DigitData/train-images.idx3-ubyte')\n",
    "y_train = parse_idx('../data/DigitData/train-labels.idx1-ubyte')\n",
    "\n",
    "x_test = parse_idx('../data/DigitData/t10k-images.idx3-ubyte')\n",
    "y_test = parse_idx('../data/DigitData/t10k-labels.idx1-ubyte')\n",
    "\n",
    "# Reshape and scale down\n",
    "p = x_train.shape[1]\n",
    "x_train = x_train.reshape(x_train.shape[0], -1) / 255.0\n",
    "x_test = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d04d5819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "train_mean = np.mean(x_train, axis=0)\n",
    "train_std = np.std(x_train, axis=0) + 1e-12\n",
    "\n",
    "x_train = (x_train - train_mean) / train_std\n",
    "x_test = (x_test - train_mean) / train_std\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, p, p) # Need (n, c, p, p) shape\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, p, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c6ffe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Network -- Values are Hyperparameters\n",
    "strides = 2\n",
    "c1 = 8\n",
    "size_k1 = 3\n",
    "size_p1 = 2\n",
    "c2 = 16\n",
    "size_k2 = 3\n",
    "size_p2 = 2\n",
    "size_d1 = 128\n",
    "k1 = Tensor(np.random.randn(c1, 1, size_k1, size_k1) * 0.01)\n",
    "C1 = Convolutional(k1)\n",
    "B1 = BatchNorm(c1)\n",
    "A1 = Activation(relu, d_relu)\n",
    "P1 = Pool(size_p1, stride=strides)\n",
    "\n",
    "k2= Tensor(np.random.randn(c2, c1, size_k2, size_k2) * 0.01)\n",
    "C2 = Convolutional(k2)\n",
    "B2 = BatchNorm(c2)\n",
    "A2 = Activation(relu, d_relu)\n",
    "P2 = Pool(size_p2, stride=strides)\n",
    "F = Flatten()\n",
    "inp_d1 = 16 * 7 * 7  # Computed based on output dims after 2 conv+pool layers\n",
    "D1 = Dense(inp_d1, size_d1)\n",
    "A3 = Activation(relu, d_relu)\n",
    "D2 = Dense(size_d1, 10)\n",
    "\n",
    "CNN = Network([C1, B1, A1, P1, C2, B2, A2, P2, F, D1, A3, D2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e91e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "LR = 0.1\n",
    "STEPS = 5000\n",
    "BATCH_SIZE = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d2873ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at Step: 1: 2.940251730889671\n",
      "Loss at Step: 101: 0.40535565322076295\n",
      "Loss at Step: 201: 0.4529225024727429\n",
      "Loss at Step: 301: 0.04657143045542067\n",
      "Loss at Step: 401: 0.41433122352158713\n",
      "Loss at Step: 501: 0.12549016288448342\n",
      "Loss at Step: 601: 0.2527259487554199\n",
      "Loss at Step: 701: 0.12577754591511955\n",
      "Loss at Step: 801: 0.01993982479395798\n",
      "Loss at Step: 901: 0.04064463454149236\n",
      "Loss at Step: 1001: 0.13915932397191136\n",
      "Loss at Step: 1101: 0.06020181930816023\n",
      "Loss at Step: 1201: 0.0822626347476682\n",
      "Loss at Step: 1301: 0.05067722566808151\n",
      "Loss at Step: 1401: 0.12148622330030573\n",
      "Loss at Step: 1501: 0.02749306986685295\n",
      "Loss at Step: 1601: 0.15826497315860585\n",
      "Loss at Step: 1701: 0.06877440545214693\n",
      "Loss at Step: 1801: 0.3089512298007142\n",
      "Loss at Step: 1901: 0.03489755529793085\n",
      "Loss at Step: 2001: 0.08518008624258185\n",
      "Loss at Step: 2101: 0.03125064774296757\n",
      "Loss at Step: 2201: 0.03666394073977903\n",
      "Loss at Step: 2301: 0.01794671946076679\n",
      "Loss at Step: 2401: 0.027030936791538163\n",
      "Loss at Step: 2501: 0.007658983094246133\n",
      "Loss at Step: 2601: 0.034628264173604234\n",
      "Loss at Step: 2701: 0.1301043996164358\n",
      "Loss at Step: 2801: 0.0030652933134092844\n",
      "Loss at Step: 2901: 0.16253946118959745\n",
      "Loss at Step: 3001: 0.029779409552234008\n",
      "Loss at Step: 3101: 0.06546029119949454\n",
      "Loss at Step: 3201: 0.001464763021516684\n",
      "Loss at Step: 3301: 0.004492640966250142\n",
      "Loss at Step: 3401: 0.027870253996584517\n",
      "Loss at Step: 3501: 0.026467817780287877\n",
      "Loss at Step: 3601: 0.06986570972451965\n",
      "Loss at Step: 3701: 0.028998009331096832\n",
      "Loss at Step: 3801: 0.032694235564000515\n",
      "Loss at Step: 3901: 0.006190884618252661\n",
      "Loss at Step: 4001: 0.018517216375222714\n",
      "Loss at Step: 4101: 0.029394574438731783\n",
      "Loss at Step: 4201: 0.026986206087530443\n",
      "Loss at Step: 4301: 0.028401619970201738\n",
      "Loss at Step: 4401: 0.013551467428254832\n",
      "Loss at Step: 4501: 0.000546984847430786\n",
      "Loss at Step: 4601: 0.2131578734838603\n",
      "Loss at Step: 4701: 0.0014896808977081556\n",
      "Loss at Step: 4801: 0.019817344921417283\n",
      "Loss at Step: 4901: 0.22372215269080845\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "grad_descent(CNN, cross_entropy, x_train, y_train, STEPS, BATCH_SIZE, LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b88274bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05977142062688339\n"
     ]
    }
   ],
   "source": [
    "# Training Loss\n",
    "CNN.set_to_predict()\n",
    "logits = CNN.forward(x_test)\n",
    "print(cross_entropy(logits.value, y_test, grad=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2ec9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy: 98.37\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(logits.value, axis=1)\n",
    "# Without hyper parameter tuning\n",
    "print(f\"Model Test Accuracy: {np.mean(preds == y_test) * 100}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
